{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link che ho trovato io : http://www.kdnuggets.com/2015/11/seven-steps-machine-learning-python.html\n",
    "\n",
    "Emilio Ferrara -_> Information science of .... south California\n",
    "\n",
    "Esempi interessanti\n",
    "\n",
    "www.gleamviz.org\n",
    "\n",
    "www.aaronkoblin.com\n",
    "\n",
    "Modello predittivo --> predire cose non note a cose note\n",
    "\n",
    "Libri interessante : <br>The Social Atom - Mark Buchanan <br>\n",
    "LEarning from Data : http://amlbook.com  --> Da comprare <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imparare una funzione che data un X ci fornisce Y.\n",
    "Si chiama supervisionato perchè c'è qualcuno che fornisce il risultato del training set.\n",
    "\n",
    "1) Approssimare il comportamento sul training set (L'agreement sul training set è molto facile)\n",
    "2) Gli algortimi generalizzano molto male ---> problema di approssimazione e generalizzazione (problema che nasce quando inizio ad applicare l'algoritmi su parti generalizzate) --> overfitting\n",
    "\n",
    "Nei big data Training Set è molto grande.\n",
    "\n",
    "LA complessità del modello va accordata con la cardinalità del training set\n",
    "\n",
    "Interessante per il machine learning l'agricoltura --> droni, immagini della terra. Come fare a ripartire le coltivazioni sulla terra\n",
    "\n",
    "--> Guardare il libro LEarning from Data : http://amlbook.com --> Da comprare \n",
    "\n",
    "Problemi di regressione -> Si sua lo squared error (devizione quadratica)\n",
    "Problemi di classificazione -> Binary Error (si o no) --> Conta gli errori\n",
    "\n",
    "in pratica si cerca di trovare una funzione g che abbia l'errore minore.\n",
    "\n",
    "**Errore in sample** IMPORTANTE -> Chiedere il risultato dell'errore (Quale è la performance della nostra performance H nel training set) -> Da chiedere a CGnal. ovvero come si comporta l'algoritmo che applica sul training set.\n",
    "\n",
    "Vogliamo poi vedere il modello **Out-of-sample error**.  -> E' la validazione retrospettivamente\n",
    "\n",
    "La cosa più semplice per gli algoritmi di definizione del modello lineare.\n",
    "\n",
    "Il più semplice si chiama **perception**.\n",
    "\n",
    "LA formula è h(x) = sign(W[trasposta]*x) --> Assume che il mio set possa essere diviso in due tramite una retta\n",
    "\n",
    "Se non posso dividere in due il mio set di dati allora devo usare una altro modelo.\n",
    "\n",
    "Allora si trasforma il set applicando una funzione non linerare. In questo modo lo porto il set in modo che possa applicato il **perception** .\n",
    "La cosa difficile è selezionare la funzione di trasformazione (normalmente usano un polinomio)\n",
    "\n",
    "LEARNING  SUPERVISED abbiamo le etichette di risultato del training set\n",
    "UNSUPERVISED LEARNING --> non ho le etichette dei risultati del training set. Il problema è riuscire a scoprire l'etichette (Topic recognition --> Fare regolazione di complessità del modello) -> il problema sono gli struttura piccole  -> La tendenza è andare verso le rete neurali su questa parte\n",
    "REINFORCEMENT LEARNING -> quando insegno al pc a giocare a scacchi e gli dico se la mossa che ha fatto è positiva o negativa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come scegliamo l'ipotesi e come valuto l'errore out of sample. -> g che abbia errore in sample piccolo ed errore out of sample piccolo\n",
    "\n",
    "Come capire se si può migliorare il modello.\n",
    "\n",
    "Per definire la dimensione del campione devi usare Hoeffending 's Inequality (valida per problemi di classificazione binaria) che varia in funzione della precisione che richiedo.\n",
    "\n",
    "(interessante il sito -> the correlator)\n",
    "\n",
    "IL problema è che non si può utilizzare l'inequality di Hoeffending nel machine learning. L'ipotesi la scegliamo a posteriori quindi non è possibile gestire la cosa con Hoeffending.\n",
    "\n",
    "Dicotomia è un hipotesi (funzione) vista solamente nell'ambito del training set\n",
    "\n",
    "VApnik --> fa in modo di limitare il numero di ipotesi\n",
    "\n",
    "\n",
    "Curva di learning.\n",
    "\n",
    "MOdello semplice --> approssima bene ma generalizza male\n",
    "Modello complesso --> approssima male ma generalizza bene (se gli dai un training set sufficentemente grande)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
